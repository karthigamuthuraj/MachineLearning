{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1b5d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"../Social_Network_Ads.csv\")\n",
    "\n",
    "# Drop 'User ID' column\n",
    "dataset.drop(columns=['User ID'], inplace=True)\n",
    "\n",
    "# Perform one-hot encoding on categorical variables\n",
    "dataset = pd.get_dummies(dataset, dtype=int, drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = dataset.drop(columns=['Purchased'])\n",
    "y = dataset['Purchased']\n",
    "\n",
    "# Split into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13f52723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  Purchased  Gender_Male\n",
       "0     19            19000          0            1\n",
       "1     35            20000          0            1\n",
       "2     26            43000          0            0\n",
       "3     27            57000          0            0\n",
       "4     19            76000          0            1\n",
       "..   ...              ...        ...          ...\n",
       "395   46            41000          1            0\n",
       "396   51            23000          1            1\n",
       "397   50            20000          1            0\n",
       "398   36            33000          0            1\n",
       "399   49            36000          1            0\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f38c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Classification Algorithms and Hyperparameters \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Create pipelines for models requiring scaling\n",
    "pipelines = {\n",
    "    'RandomForest': Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier())]),\n",
    "    'SVC': Pipeline([('scaler', StandardScaler()), ('classifier', SVC())]),\n",
    "    'KNeighbors': Pipeline([('scaler', StandardScaler()), ('classifier', KNeighborsClassifier())]),\n",
    "    'GaussianNB': Pipeline([('scaler', StandardScaler()), ('classifier', GaussianNB())]),\n",
    "    'MultinomialNB': Pipeline([('scaler', MinMaxScaler()), ('classifier', MultinomialNB())]),\n",
    "    'BernoulliNB': Pipeline([('scaler', StandardScaler()), ('classifier', BernoulliNB())]),\n",
    "    'LogisticRegression': Pipeline([('scaler', StandardScaler()), ('classifier', LogisticRegression())]),\n",
    "    'PassiveAggressive': Pipeline([('scaler', StandardScaler()), ('classifier', PassiveAggressiveClassifier())])\n",
    "}\n",
    "\n",
    "# Define the grid of hyperparameters for each model\n",
    "params = {\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [10, 50, 100],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf', 'poly']\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'GaussianNB': {},\n",
    "    'MultinomialNB': {\n",
    "        'classifier__alpha': [0.1, 1, 10]\n",
    "    },\n",
    "    'BernoulliNB': {\n",
    "        'classifier__alpha': [0.1, 1, 10]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__solver': ['lbfgs']\n",
    "    },\n",
    "    'PassiveAggressive': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__max_iter': [1000, 2000]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6d66af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Perform Grid Search with Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score,confusion_matrix\n",
    "\n",
    "results = []\n",
    "best_estimators = {}\n",
    "\n",
    "for model_name in pipelines:\n",
    "    grid_search = GridSearchCV(estimator=pipelines[model_name], param_grid=params[model_name], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimators[model_name] = grid_search.best_estimator_\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model.named_steps['classifier'], \"predict_proba\") else None\n",
    "    \n",
    "    clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else 'N/A'\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Algorithm': model_name,\n",
    "        'Best Params': grid_search.best_params_,\n",
    "        'Accuracy': clf_report['accuracy'],\n",
    "        'Precision': clf_report['weighted avg']['precision'],\n",
    "        'Recall': clf_report['weighted avg']['recall'],\n",
    "        'F1-Score': clf_report['weighted avg']['f1-score'],\n",
    "        'ROC AUC': roc_auc,\n",
    "        'Confusion Matrix': cm\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dee6922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n",
      "|     Algorithm      |                                   Best Params                                    |  Accuracy  |  Precision  |  Recall  |  F1-Score  |      ROC AUC       |  Confusion Matrix  |\n",
      "+====================+==================================================================================+============+=============+==========+============+====================+====================+\n",
      "|    RandomForest    |         {'classifier__max_depth': None, 'classifier__n_estimators': 50}          |  0.925373  |   0.92641   | 0.925373 |  0.925675  | 0.9545018007202881 |      [[79  6]      |\n",
      "|                    |                                                                                  |            |             |          |            |                    |      [ 4 45]]      |\n",
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n",
      "|        SVC         |                {'classifier__C': 1, 'classifier__kernel': 'rbf'}                 |  0.910448  |  0.913479   | 0.910448 |  0.911125  |        N/A         |      [[77  8]      |\n",
      "|                    |                                                                                  |            |             |          |            |                    |      [ 4 45]]      |\n",
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n",
      "|     KNeighbors     |        {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 5}         |  0.91791   |  0.919832   | 0.91791  |  0.918392  | 0.9411764705882354 |      [[78  7]      |\n",
      "|                    |                                                                                  |            |             |          |            |                    |      [ 4 45]]      |\n",
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n",
      "|     GaussianNB     |                                        {}                                        |  0.910448  |  0.910478   | 0.910448 |  0.909572  | 0.9608643457382953 |      [[81  4]      |\n",
      "|                    |                                                                                  |            |             |          |            |                    |      [ 8 41]]      |\n",
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n",
      "|   MultinomialNB    |                            {'classifier__alpha': 0.1}                            |  0.634328  |  0.402372   | 0.634328 |  0.492401  | 0.7150060024009603 |      [[85  0]      |\n",
      "|                    |                                                                                  |            |             |          |            |                    |      [49  0]]      |\n",
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n",
      "|    BernoulliNB     |                            {'classifier__alpha': 0.1}                            |  0.761194  |  0.763466   | 0.761194 |  0.745761  | 0.8474189675870348 |      [[78  7]      |\n",
      "|                    |                                                                                  |            |             |          |            |                    |      [25 24]]      |\n",
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n",
      "| LogisticRegression | {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'} |  0.880597  |  0.879971   | 0.880597 |  0.879429  | 0.9507803121248499 |      [[79  6]      |\n",
      "|                    |                                                                                  |            |             |          |            |                    |      [10 39]]      |\n",
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n",
      "| PassiveAggressive  |               {'classifier__C': 0.1, 'classifier__max_iter': 1000}               |  0.835821  |  0.842877   | 0.835821 |  0.828385  |        N/A         |      [[81  4]      |\n",
      "|                    |                                                                                  |            |             |          |            |                    |      [18 31]]      |\n",
      "+--------------------+----------------------------------------------------------------------------------+------------+-------------+----------+------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'results' is a list of dictionaries containing your model evaluation metrics\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame with reduced width using tabulate\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid', showindex=False, numalign=\"center\", stralign='center'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "699689e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved: RandomForest\n"
     ]
    }
   ],
   "source": [
    "#Save the Best Model using Pickle\n",
    "import pickle\n",
    "\n",
    "# Find the model with the best accuracy\n",
    "best_model_info = max(results, key=lambda x: x['Accuracy'])\n",
    "best_model_name = best_model_info['Algorithm']\n",
    "best_model = best_estimators[best_model_name]\n",
    "\n",
    "# Save the best model\n",
    "with open('best_classification_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Best model saved: {best_model_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc36b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved model\n",
    "with open('best_classification_model.pkl', 'rb') as file:\n",
    "    best_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a9a98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for custom input: 0\n"
     ]
    }
   ],
   "source": [
    "# Example custom input (ensure it matches the original features used for training)\n",
    "custom_input = pd.DataFrame([[30, 87000, 1]], columns=['Age', 'EstimatedSalary', 'Gender_Male'])\n",
    "\n",
    "# Transform the custom input using the scaler from the pipeline\n",
    "scaler = best_model.named_steps['scaler']\n",
    "custom_input_scaled = scaler.transform(custom_input)\n",
    "\n",
    "# Predict with the custom input\n",
    "custom_prediction = best_model.named_steps['classifier'].predict(custom_input_scaled)\n",
    "\n",
    "print(f\"Prediction for custom input: {custom_prediction[0]}\")\n",
    "\n",
    "#Prediction Outcome: The model predicts that, based on the input features (like Age, EstimatedSalary, Gender_Male, etc.), \n",
    "# the customer represented by your custom input (Age=30, EstimatedSalary=87000, Gender_Male=1) is predicted as not purchased (assuming 0 represents this class)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
