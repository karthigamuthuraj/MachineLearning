{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Regressor:\n",
      "Mean Squared Error: 22026496.07917349\n",
      "R² Score: 0.8581212492525863\n",
      "Best Parameters: {'learning_rate': 0.01, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tabulate import tabulate\n",
    "# Load dataset\n",
    "data = pd.read_csv('insurance_data.csv')\n",
    "data = pd.get_dummies(data, dtype=int, drop_first=True)\n",
    "# Preprocess data (Assuming 'charges' is the target variable)\n",
    "X = data.drop('charges', axis=1)\n",
    "y = data['charges']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a function for grid search and evaluation\n",
    "def grid_search_and_evaluate(model, param_grid):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R² Score: {r2}')\n",
    "    print(f'Best Parameters: {grid_search.best_params_}')\n",
    "    return best_model, r2\n",
    "\n",
    "# Store R² scores\n",
    "r2_scores = {}\n",
    "\n",
    "# AdaBoost\n",
    "ada_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0]\n",
    "}\n",
    "print(\"AdaBoost Regressor:\")\n",
    "ada_model = AdaBoostRegressor(random_state=42)\n",
    "best_ada_model, ada_r2 = grid_search_and_evaluate(ada_model, ada_param_grid)\n",
    "r2_scores['AdaBoost'] = ada_r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Regressor:\n",
      "Mean Squared Error: 18762442.407698467\n",
      "R² Score: 0.8791459213391855\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gbr_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "print(\"\\nGradient Boosting Regressor:\")\n",
    "gbr_model = GradientBoostingRegressor(random_state=42)\n",
    "best_gbr_model, gbr_r2 = grid_search_and_evaluate(gbr_model, gbr_param_grid)\n",
    "r2_scores['Gradient Boosting'] = gbr_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Regressor:\n",
      "Mean Squared Error: 18052212.982787546\n",
      "R² Score: 0.8837207054168805\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "print(\"\\nXGBoost Regressor:\")\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "best_xgb_model, xgb_r2 = grid_search_and_evaluate(xgb_model, xgb_param_grid)\n",
    "r2_scores['XGBoost'] = xgb_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM Regressor:\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 1070, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 13346.089733\n",
      "Mean Squared Error: 20046975.670354202\n",
      "R² Score: 0.8708718874690679\n",
      "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 31}\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'num_leaves': [31, 40, 50]\n",
    "}\n",
    "print(\"\\nLightGBM Regressor:\")\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "best_lgb_model, lgb_r2 = grid_search_and_evaluate(lgb_model, lgb_param_grid)\n",
    "r2_scores['LightGBM'] = lgb_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R² Scores Table:\n",
      "+-------------------+------------+\n",
      "| Algorithm         |   R² Score |\n",
      "+===================+============+\n",
      "| AdaBoost          |   0.858121 |\n",
      "+-------------------+------------+\n",
      "| Gradient Boosting |   0.879146 |\n",
      "+-------------------+------------+\n",
      "| XGBoost           |   0.883721 |\n",
      "+-------------------+------------+\n",
      "| LightGBM          |   0.870872 |\n",
      "+-------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Display the R² scores in a table format\n",
    "r2_df = pd.DataFrame.from_dict(r2_scores, orient='index', columns=['R² Score'])\n",
    "r2_df.index.name = 'Algorithm'\n",
    "\n",
    "# Display the table with borders using tabulate\n",
    "table = tabulate(r2_df, headers='keys', tablefmt='grid')\n",
    "print(\"\\nR² Scores Table:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Algorithm: XGBoost with R² Score: 0.8837207054168805\n"
     ]
    }
   ],
   "source": [
    "# Identify the best model\n",
    "best_algorithm = r2_df['R² Score'].idxmax()\n",
    "best_r2_score = r2_df['R² Score'].max()\n",
    "print(f\"\\nBest Algorithm: {best_algorithm} with R² Score: {best_r2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model and scaler saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Save the best model and scaler using pickle\n",
    "if best_algorithm == 'AdaBoost':\n",
    "    best_model = best_ada_model\n",
    "elif best_algorithm == 'Gradient Boosting':\n",
    "    best_model = best_gbr_model\n",
    "elif best_algorithm == 'XGBoost':\n",
    "    best_model = best_xgb_model\n",
    "elif best_algorithm == 'LightGBM':\n",
    "    best_model = best_lgb_model\n",
    "\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"\\nBest model and scaler saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess new input data\n",
    "def preprocess_input(new_data):\n",
    "    print(\"\\nOriginal Input Data:\")\n",
    "    print(new_data)\n",
    "\n",
    "    new_data = pd.get_dummies(new_data, dtype=int, drop_first=True)\n",
    "    print(\"\\nInput Data after Applying get_dummies:\")\n",
    "    print(new_data)\n",
    "\n",
    "    missing_cols = set(X.columns) - set(new_data.columns)\n",
    "    for col in missing_cols:\n",
    "        new_data[col] = 0\n",
    "    print(\"\\nInput Data after Adding Missing Columns:\")\n",
    "    print(new_data)\n",
    "\n",
    "    new_data = new_data[X.columns]\n",
    "    print(\"\\nInput Data Aligned with Training Data Columns:\")\n",
    "    print(new_data)\n",
    "\n",
    "    with open('scaler.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    print(\"\\nInput Data after Standardization:\")\n",
    "    print(new_data_scaled)\n",
    "\n",
    "    return new_data, new_data_scaled\n",
    "\n",
    "# Function to load the model and make predictions\n",
    "def predict(new_data):\n",
    "    with open('best_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    new_data_original, new_data_processed = preprocess_input(new_data)\n",
    "    predictions = model.predict(new_data_processed)\n",
    "    return new_data_original, new_data_processed, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Input Data:\n",
      "      age     bmi  children  sex_male  smoker_yes\n",
      "764  45.0  25.175       2.0       0.0         0.0\n",
      "\n",
      "Input Data after Applying get_dummies:\n",
      "      age     bmi  children  sex_male  smoker_yes\n",
      "764  45.0  25.175       2.0       0.0         0.0\n",
      "\n",
      "Input Data after Adding Missing Columns:\n",
      "      age     bmi  children  sex_male  smoker_yes\n",
      "764  45.0  25.175       2.0       0.0         0.0\n",
      "\n",
      "Input Data Aligned with Training Data Columns:\n",
      "      age     bmi  children  sex_male  smoker_yes\n",
      "764  45.0  25.175       2.0       0.0         0.0\n",
      "\n",
      "Input Data after Standardization:\n",
      "[[ 0.40114007 -0.89153925  0.73433626 -1.0246016  -0.50874702]]\n",
      "\n",
      "Predictions for the new input data: (      age     bmi  children  sex_male  smoker_yes\n",
      "764  45.0  25.175       2.0       0.0         0.0, array([[ 0.40114007, -0.89153925,  0.73433626, -1.0246016 , -0.50874702]]), array([10043.34], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Example usage of predict function\n",
    "new_data = pd.DataFrame([X_test.iloc[0]])  # Example input\n",
    "predictions = predict(new_data)\n",
    "print(f\"\\nPredictions for the new input data: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Input Data:\n",
      "   age  sex_male   bmi  children  smoker_yes\n",
      "0   19         1  27.9         0           1\n",
      "\n",
      "Input Data after Applying get_dummies:\n",
      "   age  sex_male   bmi  children  smoker_yes\n",
      "0   19         1  27.9         0           1\n",
      "\n",
      "Input Data after Adding Missing Columns:\n",
      "   age  sex_male   bmi  children  smoker_yes\n",
      "0   19         1  27.9         0           1\n",
      "\n",
      "Input Data Aligned with Training Data Columns:\n",
      "   age   bmi  children  sex_male  smoker_yes\n",
      "0   19  27.9         0         1           1\n",
      "\n",
      "Input Data after Standardization:\n",
      "[[-1.44710717 -0.44042221 -0.91119211  0.97598911  1.96561348]]\n",
      "\n",
      "Input Data for Predictions:\n",
      "   age   bmi  children  sex_male  smoker_yes\n",
      "0   19  27.9         0         1           1\n",
      "\n",
      "Preprocessed Input Data for Predictions:\n",
      "[[-1.44710717 -0.44042221 -0.91119211  0.97598911  1.96561348]]\n",
      "\n",
      "Predictions for the custom input data:\n",
      "[17789.484]\n"
     ]
    }
   ],
   "source": [
    "# Custom input data (example format)\n",
    "custom_data = {\n",
    "    'age': [19],\n",
    "    'sex_male': [1],\n",
    "    'bmi': [27.9],\n",
    "    'children': [0],\n",
    "    'smoker_yes': [1]\n",
    "}\n",
    "\n",
    "# Convert custom input data to DataFrame\n",
    "new_data = pd.DataFrame(custom_data)\n",
    "\n",
    "# Make predictions\n",
    "new_data_original, new_data_processed, predictions = predict(new_data)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nInput Data for Predictions:\")\n",
    "print(new_data_original)\n",
    "print(\"\\nPreprocessed Input Data for Predictions:\")\n",
    "print(new_data_processed)\n",
    "print(\"\\nPredictions for the custom input data:\")\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
